---
title: "connect to dbs"
format: html
editor: visual
---

```{r}
library(connections)
library(RSQLite)
library(DBI)
library(tidyverse)
library(dbplyr)

con <- connection_open(RSQLite::SQLite(), "mimic4.db")
```

we can use tbl() to take a reference to tables in teh database

```{r}
labevents <- tbl(con, "labevents")
```

## Generating queries

To interact with a database you usually use SQL, the Structured Query Language. The goal of dbplyr is to automatically generate SQL for you so that you're not forced to use it.

Most of the time you don't need to know anything about SQL, and you can continue to use the dplyr verbs that you're already familiar with:

```{r}
# Without Joins

labevents

```

```{r}
labevents |>
  select(subject_id,itemid,value)
```

```{r}
labevents |>
  filter(priority == "STAT")
```

```{r}
labevents |>
  group_by(specimen_id) |>
  summarise(resultss_per_spec = n())
```

The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database on the remote server, not in R on your local machine. When working with databases, dplyr tries to be as lazy as possible:

It never pulls data into R unless you explicitly ask for it.

It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step.

For example, take the following code:

```{r}
spec_tests_db <- labevents |>
  group_by(specimen_id) |> 
summarise(
    n = n(),
    abnormals = sum(is.na(flag))/as.numeric(n())
    ) |>
  arrange(desc(abnormals)) %>%
  filter(n > 30)
```

This long pipeline of operations never touches the database. It's not until you ask for the data (e.g. by printing `spec_tests_db`) that dplyr generates the SQL and requests the results from the database. Even then it tries to do as little work as possible and only pulls down a few rows.

```{r}
spec_tests_db
```

Behind the scenes, dplyr is translating your R code into SQL. You can see the SQL it's generating with `show_query()`:

```{r}
spec_tests_db %>% show_query()
```

Typically, you'll iterate a few times before you figure out what data you need from the database. Once you've figured it out, use `collect()` to pull all the data down into a local tibble:

```{r}
spec_tests <- spec_tests_db %>% collect()
spec_tests
```

`collect()` requires that database does some work, so it may take a long time to complete. Otherwise, dplyr tries to prevent you from accidentally performing expensive query operations:

-   Because there's generally no way to determine how many rows a query will return unless you actually run it, `nrow()` is always `NA`.

-   Because you can't find the last few rows without executing the whole query, you can't use `tail()`.
